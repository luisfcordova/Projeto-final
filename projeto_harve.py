# -*- coding: utf-8 -*-
"""projeto harve

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dbxXdyTpgLhYJk_hjz9w_heLbwwK35cR

Projeto de conclusão de curso de analise de dados pela Harve, onde estudamos a base de da Olist, onde analisamos os produtos mais vendidos, satisfação do produto, local de compra e valores.

Luis Felipe Cordova
"""

import matplotlib.pyplot as plt
import seaborn as sns

cm = ["#273176","#3B61A3","#76A4AC","#BFD4B2","#DAD8A1"]
gradient = ["#292F55","#273176","#223A92","#3B61A3",
            "#76A4AC","#BFD4B2","#DAD8A1","#C7B679","#957447"]

plt.rcParams['axes.spines.top'] = False
plt.rcParams['axes.spines.right'] = False

sns.palplot(gradient)
plt.show()

#importando tabelas

import pandas as pd

customers  = pd.read_csv("https://harve.com.br/praticas/olist/olist_customers_dataset.csv")
geolocation  = pd.read_csv("https://harve.com.br/praticas/olist/olist_geolocation_dataset.csv")
order_items = pd.read_csv("https://harve.com.br/praticas/olist/olist_order_items_dataset.csv")
payments = pd.read_csv("https://harve.com.br/praticas/olist/olist_order_payments_dataset.csv")
df_reviews = pd.read_csv("https://harve.com.br/praticas/olist/olist_order_reviews_dataset.csv")
orders = pd.read_csv("https://harve.com.br/praticas/olist/olist_orders_dataset.csv")
products = pd.read_csv("https://harve.com.br/praticas/olist/olist_products_dataset.csv")
sellers = pd.read_csv("https://harve.com.br/praticas/olist/olist_sellers_dataset.csv")
product_category_name_translation  = pd.read_csv("https://harve.com.br/praticas/olist/product_category_name_translation.csv")

#criando df
df_olist_orders = pd.read_csv("https://harve.com.br/praticas/olist/olist_orders_dataset.csv")
df_reviews = pd.read_csv("https://harve.com.br/praticas/olist/olist_order_reviews_dataset.csv")
df_order_items = pd.read_csv("https://harve.com.br/praticas/olist/olist_order_items_dataset.csv")
df_products = pd.read_csv("https://harve.com.br/praticas/olist/olist_products_dataset.csv")



#alterando de obj para data
df_olist_orders['order_approved_at'] = pd.to_datetime(df_olist_orders['order_approved_at'])
df_olist_orders['order_purchase_timestamp'] = pd.to_datetime(df_olist_orders['order_purchase_timestamp'])
df_olist_orders['order_delivered_customer_date'] = pd.to_datetime(df_olist_orders['order_delivered_customer_date'])
df_olist_orders['order_estimated_delivery_date'] = pd.to_datetime(df_olist_orders['order_estimated_delivery_date'])

""" .Qual é o tempo médio/mediano desde a aprovação do pedido até a sua entrega?

"""

orders_filtrado = df_olist_orders['dias_entregas'] = df_olist_orders['order_delivered_customer_date'] - df_olist_orders['order_approved_at']
orders_filtrado = df_olist_orders[(df_olist_orders['order_status'] == 'delivered') & (df_olist_orders['order_delivered_customer_date'] >= df_olist_orders['order_approved_at'])]

average_delivery_time = orders_filtrado['dias_entregas'].mean()
med_delivery_time = orders_filtrado['dias_entregas'].median()

print(f"O tempo médio de entrega desde a aprovação até a entrega ao cliente é {average_delivery_time}")
print(f"O tempo mediano da entrega é de {med_delivery_time}")

"""Identificar qual o mês com maior quantidade de vendas (em número de pedido) e o mês com os maiores
pagamentos (pagamentos)

"""

import matplotlib.pyplot as plt
orders_payments = pd.merge(payments, orders, on='order_id', how='left')


orders_payments['order_purchase_timestamp'] = pd.to_datetime(orders_payments['order_purchase_timestamp'])
orders_payments['order_approved_at'] = pd.to_datetime(orders_payments['order_approved_at'])


orders_payments['mês/ano'] = orders_payments['order_purchase_timestamp'].dt.strftime('%m-%Y')


orders_payments['mês/ano'] = pd.to_datetime(orders_payments['mês/ano'], format='%m-%Y')

vendas_mes = orders_payments.groupby('mês/ano')['order_id'].count()


mes_com_mais_vendas = vendas_mes.idxmax()
quantidade_vendas = vendas_mes.max()

print(f'Mês com o maior número de vendas: {mes_com_mais_vendas}')
print(f'Número de vendas nesse mês: {quantidade_vendas}')

plt.figure(figsize=(10, 6))
plt.plot(vendas_mes.index, vendas_mes.values, marker='o', color='b', label='Quantidade de Vendas', linestyle='-', markersize=5)
plt.title('Quantidade de Vendas por Mês/ano', fontsize=14)
plt.xlabel('Mês/Ano', fontsize=12)
plt.ylabel('Número de Vendas', fontsize=12)
plt.xticks(rotation=45)
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

# Convertendo as colunas de data para datetime
orders_payments['order_purchase_timestamp'] = pd.to_datetime(orders_payments['order_purchase_timestamp'])
orders_payments['order_approved_at'] = pd.to_datetime(orders_payments['order_approved_at'])

# Extraindo mês e ano da data de compra e criando a coluna 'mês/ano'
orders_payments['mês/ano'] = orders_payments['order_purchase_timestamp'].dt.strftime('%m-%Y')

# Convertendo 'mês/ano' para datetime
orders_payments['mês/ano'] = pd.to_datetime(orders_payments['mês/ano'], format='%m-%Y')

# Agrupando por 'mês/ano' e somando os valores de pagamento 'payment_value'
pagamentos_mes = orders_payments.groupby('mês/ano')['payment_value'].sum()

# Encontrando o mês com o maior valor de pagamento
mes_com_maior_pagamento = pagamentos_mes.idxmax()
maior_pagamento = pagamentos_mes.max()

# Exibindo o resultado
print(f'Mês com o maior valor de pagamentos: {mes_com_maior_pagamento}')
print(f'Valor total de pagamentos nesse mês: R$ {maior_pagamento:,.2f}')

plt.figure(figsize=(10, 6))
plt.plot(pagamentos_mes.index, pagamentos_mes.values, marker='o', color='g', label='Valor de Pagamentos', linestyle='-', markersize=5)
plt.title('Valor Total de Pagamentos por Mês/ano', fontsize=14)
plt.xlabel('Mês/Ano', fontsize=12)
plt.ylabel('Valor Total de Pagamentos (R$)', fontsize=12)
plt.xticks(rotation=45)
plt.grid(True)
plt.legend()
plt.tight_layout()
plt.show()

"""3. Avalie a satisfação dos clientes: i) notas; ii) estão realizando comentários?

"""

import pandas as pd

# Funções
def comentarios(review_comment_message):
    if review_comment_message == "" or pd.isna(review_comment_message):
        return "Não"
    else:
        return "Sim"

def nota_review(review_score):
    if review_score == 5:
        return "Muito bom"
    elif review_score == 4:
        return "Bom"
    elif review_score == 3:
        return "Médio"
    else:
        return "Ruim"

# Criação das colunas
df_reviews['Comentários'] = df_reviews['review_comment_message'].apply(comentarios)
df_reviews['Classificação pedido'] = df_reviews['review_score'].apply(nota_review)

# Quantidade de comentários por nota
qtd_com = df_reviews[df_reviews['Comentários'] == 'Sim']['review_score'] \
            .value_counts().sort_index().reset_index()
qtd_com.columns = ['review_score', 'qtd_comentarios']

# Quantidade total por nota
qtd_total = df_reviews['review_score'] \
              .value_counts().sort_index().reset_index()
qtd_total.columns = ['review_score', 'qtd_total']

# Junta as duas bases
dist = qtd_com.merge(qtd_total, on='review_score', how='right')

# Calcula a porcentagem
dist['Porcentagem'] = (dist['qtd_comentarios'] / dist['qtd_total'] * 100).round(2)

dist

#questao ii
def comentarios(review_comment_message):
    if review_comment_message == "" or pd.isna(review_comment_message):
        return "Não"
    else:
        return "Sim"
df_reviews['Comentários']=df_reviews['review_comment_message'].apply(comentarios)
porcentagem = df_reviews['Comentários'].value_counts(normalize=True).reindex(['Sim', 'Não']) * 100
porcentagem = porcentagem.reset_index()

porcentagem[porcentagem['Comentários'] == 'Não']['proportion'].values[0]
print(f"Cerca de {porcentagem[porcentagem['Comentários'] == 'Não']['proportion'].values[0].round(2)}% não estão engajados em realizar avaliações dos produtos adquiridos.")

"""4. Existe algum padrão entre a satisfação do cliente com a entrega antes ou depois do prazo previsto?"""

# Create copy not to change the original dataset
orders_treated = orders.copy()

# Convert date columns to datetime
orders_treated['order_estimated_delivery_date'] = pd.to_datetime(orders_treated['order_estimated_delivery_date'])
orders_treated['order_delivered_customer_date'] = pd.to_datetime(orders_treated['order_delivered_customer_date']).dt.normalize()

# Create new column to indicate if the order was delayed
orders_treated['delayed'] = orders_treated['order_delivered_customer_date'] > orders_treated['order_estimated_delivery_date']

orders_w_reviews = orders_treated.merge(reviews)

to_graph = orders_w_reviews.groupby('delayed')['review_score'].mean().reset_index()

to_graph['delayed'] = to_graph['delayed'].astype(str)

to_graph['review_score'] = round(to_graph['review_score'], 2)

display(to_graph)

to_graph_2 = orders_w_reviews.groupby(['review_score', 'delayed'])['order_id'].count().unstack().reset_index()

to_graph_2['per_delayed'] = 100 * to_graph_2[True] / (to_graph_2[True] + to_graph_2[False])

# Gráfico 1
bars1 = plt.bar(
    x=to_graph['delayed'],
    height=to_graph['review_score'], color=cm
)
plt.bar_label(bars1, padding=3)

plt.show()

display(to_graph_2)

# Gráfico 2
bars1 = plt.bar(
    x=to_graph_2['review_score'],
    height=to_graph_2['per_delayed'], color=cm
)
plt.bar_label(bars1, padding=3)  # <-- rótulos

plt.show()

"""Quais as categorias de produtos mais vendidos? E os menos vendidos? Existe relação com os preços dos itens? A quantidade de fotos impacta nas vendas?

1-
"""

import pandas as pd

df_order_items = pd.read_csv("https://harve.com.br/praticas/olist/olist_order_items_dataset.csv")
df_products = pd.read_csv("https://harve.com.br/praticas/olist/olist_products_dataset.csv")

df_products_orders = pd.merge(df_order_items, df_products, on='product_id', how='inner')

import seaborn as sns
import matplotlib.pyplot as plt

# Merge DFs
df_merge = order_items.merge(products, how='inner')
df_to_graph = df_merge.groupby('product_category_name')['order_id'].nunique().reset_index()
df_aux = df_merge.groupby('product_category_name')['price'].mean().reset_index()
df_to_graph = df_to_graph.merge(df_aux)
df_aux = df_merge.groupby('product_category_name')['product_photos_qty'].mean().reset_index()
df_to_graph = df_to_graph.merge(df_aux)

# Define bins (0–1000, then "1000+")
bins = list(range(0, 1100, 100))  # [0,100,200,...,1000]
labels = [f"{i}-{i+100}" for i in bins[:-2]] + ["900-1000"]

df_to_graph['faixa_preco'] = pd.cut(df_to_graph['price'], bins=bins, labels=labels, right=False, include_lowest=True)

display(df_to_graph.sort_values('order_id', ascending=False).head())

print('\n')

display(df_to_graph.sort_values('order_id', ascending=True).head())

df_to_graph_2 = df_to_graph.groupby('faixa_preco')['order_id'].sum().reset_index()

display(df_to_graph_2)

fig, ax = plt.subplots(2, 2, figsize=[10, 10])

sns.scatterplot(x=df_to_graph['price'], y=df_to_graph['order_id'], ax=ax[0][0])
sns.scatterplot(x=df_to_graph['product_photos_qty'], y=df_to_graph['order_id'], ax=ax[0][1])

# Gráfico 3
bars1 = ax[1][0].barh(
    y=df_to_graph_2['faixa_preco'],
    width=df_to_graph_2['order_id'], color=cm
)
ax[1][0].bar_label(bars1, padding=3)  # <-- rótulos

import numpy as np
corr = df_to_graph[['order_id', 'price', 'product_photos_qty']].corr()
print('\n')

display(corr)
matrix = np.triu(corr, k=1)
sns.heatmap(corr, cmap="viridis", annot=True, mask=matrix, ax=ax[1][1])

plt.show()

### Second price analisys

df_to_graph = df_merge.groupby('product_id')['order_id'].nunique().reset_index()
df_aux = df_merge.groupby('product_id')['price'].mean().reset_index()
df_to_graph = df_to_graph.merge(df_aux)
df_to_graph = df_merge.groupby('product_id')['order_id'].nunique().reset_index()
df_aux = df_merge.groupby('product_id')['price'].mean().reset_index()
df_to_graph = df_to_graph.merge(df_aux)
df_aux = df_merge.groupby('product_id')['product_photos_qty'].mean().reset_index()
df_to_graph = df_to_graph.merge(df_aux)

print('\n Análise por produto:')

fig, ax = plt.subplots(1, 3, figsize=[10, 5])

sns.scatterplot(x=df_to_graph['price'], y=df_to_graph['order_id'], ax=ax[0])
sns.scatterplot(x=df_to_graph['product_photos_qty'], y=df_to_graph['order_id'], ax=ax[1])

corr = df_to_graph[['order_id', 'price', 'product_photos_qty']].corr()
print('\n')

display(corr)
matrix = np.triu(corr, k=1)
sns.heatmap(corr, cmap="viridis", annot=True, mask=matrix, ax=ax[2])

plt.show()

""" A quantidade de fotos impacta nas vendas?"""

import seaborn as sns

df_merge = order_items.merge(products, how='inner')
df_to_graph = df_merge.groupby('product_category_name')['order_id'].nunique().reset_index()
df_aux = df_merge.groupby('product_category_name')['price'].mean().reset_index()
df_to_graph = df_to_graph.merge(df_aux)
df_aux = df_merge.groupby('product_category_name')['product_photos_qty'].mean().reset_index()
df_to_graph = df_to_graph.merge(df_aux)
display(df_to_graph.sort_values('order_id', ascending=False).head())

sns.violinplot(data=df_to_graph, x='price', orient='h')

"""6. O volume e o peso dos produtos impactam no valor do frete?"""

import seaborn as sns
import matplotlib.pyplot as plt

merge_df = order_items.merge(products)[['freight_value', 'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']]
merge_df['cm3'] = merge_df['product_length_cm'] * merge_df['product_height_cm'] * merge_df['product_width_cm']

fig, ax = plt.subplots(1, 3, figsize=[15, 5])

sns.scatterplot(x = merge_df['freight_value'], y = merge_df['product_weight_g'], ax=ax[0])
sns.scatterplot(x = merge_df['freight_value'], y = merge_df['cm3'], ax=ax[1])
corr = merge_df[['freight_value', 'product_weight_g', 'cm3']].corr()
display(corr)
matrix = np.triu(corr, k=1)
sns.heatmap(corr, cmap="viridis", annot=True, mask=matrix)

"""Avaliação/Visualização da posição geográfica onde se encontra a maior concentração de clientes e
vendedores;

"""

import geopandas as gpd
import matplotlib.pyplot as plt

df_merge = customers.merge(geolocation, left_on='customer_zip_code_prefix', right_on='geolocation_zip_code_prefix')
df_merge.drop_duplicates(subset='customer_unique_id', inplace=True)

import folium
from folium.plugins import MarkerCluster

# 1) Limpeza básica
df_cli_plot = (df_merge
               .dropna(subset=["geolocation_lat","geolocation_lng"])
               .query("-34 <= geolocation_lat <= 5 and -74 <= geolocation_lng <= -34")  # opcional: BR
               )

# 2) Mapa
m = folium.Map(location=[-15.78, -47.93], zoom_start=4, tiles="cartodbpositron")

cluster = MarkerCluster(name="Clientes").add_to(m)
for lat, lng in zip(df_cli_plot["geolocation_lat"], df_cli_plot["geolocation_lng"]):
    folium.CircleMarker(
        location=[lat, lng],
        radius=3, color="blue", fill=True, fill_opacity=0.6
    ).add_to(cluster)

folium.LayerControl().add_to(m)

print('Clientes:')
display(m)

import geopandas as gpd
import matplotlib.pyplot as plt

df_merge = sellers.merge(geolocation, left_on='seller_zip_code_prefix', right_on='geolocation_zip_code_prefix')
df_merge.drop_duplicates(subset='seller_id', inplace=True)

import folium
from folium.plugins import MarkerCluster

# 1) Limpeza básica
df_cli_plot = (df_merge
               .dropna(subset=["geolocation_lat","geolocation_lng"])
               .query("-34 <= geolocation_lat <= 5 and -74 <= geolocation_lng <= -34")  # opcional: BR
               )

# 2) Mapa
m = folium.Map(location=[-15.78, -47.93], zoom_start=4, tiles="cartodbpositron")

cluster = MarkerCluster(name="Clientes").add_to(m)
for lat, lng in zip(df_cli_plot["geolocation_lat"], df_cli_plot["geolocation_lng"]):
    folium.CircleMarker(
        location=[lat, lng],
        radius=3, color="blue", fill=True, fill_opacity=0.6
    ).add_to(cluster)

folium.LayerControl().add_to(m)

print('Clientes:')
display(m)

display(customers['customer_state'].value_counts())
display(sellers['seller_state'].value_counts())

"""8. As entregas atrasadas aconteceram entre vendedores/compradores de estados diferentes?"""

df_merge = orders.merge(customers).merge(order_items).merge(sellers)

# df somente com estados diferentes
df_different_state = df_merge[df_merge['customer_state'] != df_merge['seller_state']].copy()
df_different_state.drop_duplicates(subset='order_id', inplace=True)
df_different_state['estado_diferente'] = 'Estado diferente'


df_same_state = df_merge[df_merge['order_id'].isin(df_different_state['order_id']) == False].copy()
df_same_state.drop_duplicates(subset='order_id', inplace=True)
df_same_state['estado_diferente'] = 'Mesmo estado'

df_concat = pd.concat([df_same_state, df_different_state])

df_concat['order_estimated_delivery_date'] = pd.to_datetime(df_concat['order_estimated_delivery_date'])
df_concat['order_delivered_customer_date'] = pd.to_datetime(df_concat['order_delivered_customer_date']).dt.normalize()

df_concat['delayed'] = df_concat['order_delivered_customer_date'] > df_concat['order_estimated_delivery_date']

df_graph = df_concat.groupby('estado_diferente')['order_id'].nunique().reset_index()
df_graph.rename(columns={'order_id' : 'total_pedidos'}, inplace=True)

df_aux_delayed = df_concat[df_concat['delayed']].groupby('estado_diferente')['order_id'].nunique().reset_index()

df_graph = df_graph.merge(df_aux_delayed, how='left')
df_graph.rename(columns={'order_id' : 'pedidos_atrasados'}, inplace=True)

df_graph['per_atrasados'] = df_graph['pedidos_atrasados'] / df_graph['total_pedidos']

display(df_graph.style.format({"per_atrasados": "{:.1%}"}))

df_graph['per_atrasados'] = round(df_graph['per_atrasados'] * 100, 1)

# Gráfico 1
bars1 = plt.bar(
    x=df_graph['estado_diferente'],
    height=df_graph['per_atrasados'], color=cm
)
plt.bar_label(bars1, padding=3)  # <-- rótulos

plt.show()

df_pivot = df_merge.groupby(['seller_state', 'customer_state'])['order_id'].count().unstack()
df_pivot = df_pivot.fillna(0)
df_pivot = 100 * df_pivot / df_merge['order_id'].count()
df_pivot.style.format("{:.2f}%").background_gradient(cmap='Blues')

"""9. Identificar o padrão dos clientes (localização, método de pagamento, quantidade de parcelas, entrega antes da previsão, notas de satisfação média, tipos de produtos) que fizeram uma recompra no site;"""

### Function to calculate %

def calc_per(df, column_group, column_total ,column_per):
  df_treat = df.groupby(column_group)[column_total].count().reset_index()
  df_treat.rename(columns={column_total : 'total'}, inplace=True)
  df_aux = df[df[column_per]].groupby(column_group)[column_total].nunique().reset_index()
  df_aux.rename(columns={column_total : 'total_' + column_per}, inplace=True)
  df_treat = df_treat.merge(df_aux)
  df_treat['per_' + column_per] = df_treat[ 'total_' + column_per] / df_treat['total']

  return df_treat

### Group recurrent customers
df_rec_customers = customers.groupby('customer_unique_id')['customer_id'].count().reset_index()
df_rec_customers = df_rec_customers[df_rec_customers['customer_id'] > 1]

### Merge with orders and create recurrent column
df_merge = orders.merge(customers)
df_merge['Recorrente'] = False
df_merge.loc[df_merge['customer_unique_id'].isin(df_rec_customers['customer_unique_id']), 'Recorrente'] = True

# Convert date columns to datetime
df_merge['order_estimated_delivery_date'] = pd.to_datetime(df_merge['order_estimated_delivery_date'])
df_merge['order_delivered_customer_date'] = pd.to_datetime(df_merge['order_delivered_customer_date']).dt.normalize()

# Create new column to indicate if the order was delayed
df_merge['delayed'] = df_merge['order_delivered_customer_date'] > df_merge['order_estimated_delivery_date']

### Use function to calculate percentagem os recurrent clients per state
df_new = calc_per(df_merge, 'customer_state', 'order_id', 'Recorrente')

display(df_new.sort_values('per_Recorrente', ascending=False).style.format({"per_Recorrente": "{:.1%}"}))

### Merge with reviews to see if average os recurrent clientes is higher
df_merge_reviews = df_merge.merge(reviews)
df_merge_reviews.drop_duplicates(subset='review_id', inplace=True)

display(df_merge_reviews.groupby('Recorrente')['review_score'].mean())

### Use function to calculate percentagem os recurrent clients when delivery is delayed
df_new = calc_per(df_merge, 'delayed', 'order_id', 'Recorrente')

display(df_new.sort_values('per_Recorrente', ascending=False).style.format({"per_Recorrente": "{:.1%}"}))

